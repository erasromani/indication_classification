{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = {\n",
    "  \"train\": 0.4,\n",
    "  \"val\": 0.2,\n",
    "  \"test\": 0.4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_data = 500\n",
    "seed = 42\n",
    "current_datetime = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(split.values()) == 1, \"split values must sum to 1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "  \"(high-risk) screening\": \"(high-risk) screening\",\n",
    "  \"6-month follow-up / surveillance\": \"6-month follow-up / surveillance\",\n",
    "  \"additional workup\": \"additional workup\",\n",
    "  \"exclude\": \"exclude\",\n",
    "  \"extent of disease / pre-operative planning\": \"extent of disease / pre-operative planning\",\n",
    "  \"unknown\": \"unknown\",\n",
    "  \"treatment monitoring\": \"exclude\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(data):\n",
    "  text = data['task']['data']\n",
    "  id = data['task']['id']\n",
    "  found = False\n",
    "  for result in data['result']:\n",
    "    label_name = result['from_name']\n",
    "    if label_name == 'indication':\n",
    "      found = True\n",
    "      label = result['value']['choices'][0]\n",
    "      assert len(result['value']['choices']) == 1, f'more than one label selected for task {id}'\n",
    "  if not found:\n",
    "    print(f'no indication label found for task {id}')\n",
    "    return None\n",
    "  else:\n",
    "    return {\n",
    "      'id': id,\n",
    "      'text': text,\n",
    "      'label': label_mapping[label]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/gpfs/data/geraslab/ekr6072/projects/study_indication/data')\n",
    "output_path = data_dir / 'dataset.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = list(data_dir.rglob('label_studio/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no indication label found for task 3858\n",
      "no indication label found for task 3814\n",
      "no indication label found for task 3899\n",
      "no indication label found for task 3871\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "for data_path in data_paths:\n",
    "  with open(data_path, 'r') as f: \n",
    "    task = json.load(f)\n",
    "  data = extract_info(task)\n",
    "  if data is not None:\n",
    "    dataset.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for data in dataset:\n",
    "  id = data['id']\n",
    "  ids.append(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_indices = np.argsort(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.permutation(sort_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_max_id = int(split['train'] * num_data)\n",
    "val_max_id = int(split['val'] * num_data) + train_max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = indices[:train_max_id]\n",
    "val_indices = indices[train_max_id:val_max_id]\n",
    "test_indices = indices[val_max_id:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(dataset, indices):\n",
    "  dataset = np.array(dataset)\n",
    "  return list(dataset[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_items(dataset, train_indices)\n",
    "val_ds = get_items(dataset, val_indices)\n",
    "test_ds = get_items(dataset, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {\n",
    "  \"train\": train_ds,\n",
    "  \"val\": val_ds,\n",
    "  \"test\": test_ds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path, 'wb') as f:\n",
    "  pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_string = datetime.datetime.strftime(current_datetime, \"%Y%m%d\")\n",
    "time_string = datetime.datetime.strftime(current_datetime, \"%H%M%S\")\n",
    "datetime_string = datetime.datetime.strftime(current_datetime, \"%Y%m%dT%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = data_dir / 'logs' / date_string / time_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = {}\n",
    "for subset in dataset: \n",
    "  f[subset] = open(os.path.join(log_dir, f'{subset}_task_ids.log'), 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in dataset:\n",
    "  f[subset].write(\"task_id\\n\")\n",
    "  for task in dataset[subset]:\n",
    "    id = task[\"id\"]\n",
    "    f[subset].write(f\"{id}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in dataset: \n",
    "  f[subset].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = re.compile(r'ACCESSION_NUMBER: ([A-Z]*[0-9]*)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = {}\n",
    "for subset in dataset: \n",
    "  f[subset] = open(os.path.join(log_dir, f'{subset}_acns.log'), 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in dataset:\n",
    "  f[subset].write(\"acn\\n\")\n",
    "  for data in dataset[subset]:\n",
    "    meta = data['text']['meta']\n",
    "    acn = pattern.findall(meta)\n",
    "    assert len(acn) == 1, 'invalid number of accession numbers found in metadata'\n",
    "    f[subset].write(f\"{acn[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subset in dataset: \n",
    "  f[subset].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ed162c912b93bb002fbfa43104448fd591708b144c0f60609ae8c85351539a1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('fusion': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
