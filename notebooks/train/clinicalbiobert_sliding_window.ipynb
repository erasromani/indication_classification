{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import f1_score\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/gpfs/data/geraslab/ekr6072/projects/study_indication/data')\n",
    "data_path = data_dir / 'dataset.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'rb') as f:\n",
    "  dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "  output = {}\n",
    "  for name, subset in dataset.items():\n",
    "    clean_subset = []\n",
    "    for data in subset:\n",
    "      label = data['label']\n",
    "      if label not in ['unknown']:\n",
    "        clean_subset.append(data)\n",
    "    output[name] = clean_subset\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = clean_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "category2id = {\n",
    "  '(high-risk) screening': 0,\n",
    "  'extent of disease / pre-operative planning': 1,\n",
    "  'additional workup': 2,\n",
    "  '6-month follow-up / surveillance': 3,\n",
    "  'exclude': 4,\n",
    "  'unknown': 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = [data['text']['longText'] for data in dataset['train']]\n",
    "train_labels = [category2id[data['label']] for data in dataset['train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_texts = [data['text']['longText'] for data in dataset['val']]\n",
    "val_labels = [category2id[data['label']] for data in dataset['val']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=False, padding=False)\n",
    "val_encodings = tokenizer(val_texts, truncation=False, padding=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_pad(data, padding_idx, max_length=512):\n",
    "  num_tokens = len(data)\n",
    "  data = torch.tensor(data)\n",
    "  num_no_pad = (num_tokens // max_length)\n",
    "  pad_token_count = num_tokens - num_no_pad * max_length\n",
    "  num_sections = num_no_pad if pad_token_count == 0 else num_no_pad + 1\n",
    "  output = torch.zeros((num_sections, max_length), dtype=int) + padding_idx\n",
    "  for i in range(num_sections):\n",
    "    if i < num_sections - 1:\n",
    "      output[i, :] = data[i*max_length:(i+1)*max_length]\n",
    "    else:\n",
    "      final_section = data[i*max_length:]\n",
    "      output[i, :len(final_section)] = final_section\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_transform(encoding, dataset, padding_idx, max_length=512, return_metadata=False):  \n",
    "  outputs = []\n",
    "  if return_metadata: metadata = []\n",
    "  for i, data in enumerate(encoding):\n",
    "    output = split_pad(data, padding_idx, max_length=max_length)\n",
    "    if return_metadata: metadata.extend([dataset[i]['id'] for _ in output])\n",
    "    outputs.append(output)\n",
    "  if return_metadata:\n",
    "    metadata = pd.DataFrame({\"id\": metadata}).groupby(\"id\")\n",
    "    return torch.cat(outputs), [data.index.values for _, data in metadata]\n",
    "  return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_transform(encoding, dataset, padding_idx, max_length=512, return_metadata=False):  \n",
    "  outputs = []\n",
    "  if return_metadata: metadata = []\n",
    "  for i, data in enumerate(encoding):\n",
    "    output = split_pad(data, padding_idx, max_length=max_length)\n",
    "    if return_metadata: metadata.extend([dataset[i]['id'] for _ in output])\n",
    "    outputs.append(output)\n",
    "  if return_metadata:\n",
    "    metadata = pd.DataFrame({\"id\": metadata})\n",
    "    return torch.cat(outputs), metadata\n",
    "  return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_encodings(encodings, dataset, padding_idx, max_length=512):  \n",
    "  input_ids, metadata = sliding_window_transform(encodings['input_ids'], dataset, padding_idx, max_length=max_length, return_metadata=True)\n",
    "  token_type_ids = sliding_window_transform(encodings['token_type_ids'], dataset, 0, max_length=max_length)\n",
    "  attention_mask = sliding_window_transform(encodings['attention_mask'], dataset, 0, max_length=max_length)\n",
    "  return {\n",
    "    \"input_ids\": input_ids,\n",
    "    \"token_type_ids\": token_type_ids,\n",
    "    \"attention_mask\": attention_mask,\n",
    "    \"metadata\": metadata\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class IndicationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, metadata, labels):\n",
    "        self.encodings = encodings\n",
    "        self.metadata = metadata\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        label = self.labels[idx]\n",
    "        id = self.metadata[idx]['id']    \n",
    "        item['id'] = id\n",
    "        item['label'] = label\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = IndicationDataset(train_encodings, dataset['train'], train_labels)\n",
    "val_dataset = IndicationDataset(val_encodings, dataset['val'], val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_transform(encoding, dataset, padding_idx, max_length=512, return_metadata=False):  \n",
    "  outputs = []\n",
    "  if return_metadata: metadata = []\n",
    "  for i, data in enumerate(encoding):\n",
    "    output = split_pad(data, padding_idx, max_length=max_length)\n",
    "    if return_metadata: metadata.extend([dataset[i]['id'] for _ in output])\n",
    "    outputs.append(output)\n",
    "  if return_metadata:\n",
    "    metadata = pd.DataFrame({\"id\": metadata})\n",
    "    return torch.cat(outputs), metadata\n",
    "  return torch.cat(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch, padding_idx=0, max_length=512):\n",
    "  outputs = defaultdict(list)\n",
    "  metadata = []\n",
    "  for sample in batch:\n",
    "    input_ids = split_pad(sample['input_ids'], 0, max_length=512)\n",
    "    token_type_ids = split_pad(sample['token_type_ids'], 0, max_length=512)\n",
    "    attention_mask = split_pad(sample['attention_mask'], 0, max_length=512)\n",
    "    repeat = input_ids.shape[0]\n",
    "    metadata.extend([sample['id'] for _ in range(repeat)])\n",
    "    label = torch.tensor(sample['label']).repeat(repeat)\n",
    "\n",
    "    outputs['input_ids'].append(input_ids)\n",
    "    outputs['token_type_ids'].append(token_type_ids)\n",
    "    outputs['attention_mask'].append(attention_mask)\n",
    "    outputs['labels'].append(label)\n",
    "  \n",
    "  outputs = {key: torch.cat(val) for key, val in outputs.items()}\n",
    "  outputs['metadata'] = pd.DataFrame({\"id\": metadata})\n",
    "  return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, 4, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, 4, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ClinicalBERT(nn.Module):\n",
    "  def __init__(self, num_classes, reduction='mean'):\n",
    "      super(ClinicalBERT, self).__init__()\n",
    "      self.bert = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "      self.linear = nn.Linear(768, num_classes)\n",
    "      self.loss_func = nn.CrossEntropyLoss()\n",
    "      self.reduction = reduction\n",
    "  \n",
    "  def forward(self, **kwargs):\n",
    "    x = self.bert(input_ids=kwargs['input_ids'], attention_mask=kwargs['attention_mask'])\n",
    "    logits = self.linear(x['pooler_output'])\n",
    "    reduced_logits = []\n",
    "    labels = []\n",
    "    for _, meta in kwargs['metadata'].groupby('id'):\n",
    "      indices = meta.index.values\n",
    "      if self.reduction == 'mean':\n",
    "        reduced_logits.append(logits[indices].mean(axis=0))\n",
    "      elif self.reduction == 'max':\n",
    "        reduced_logits.append(logits[indices].max(axis=0).values)\n",
    "      else:\n",
    "        ValueError(f'invalid reduction value {self.reduction} entered')\n",
    "      label = kwargs['labels'][indices][0]\n",
    "      labels.append(label)\n",
    "    labels = torch.stack(labels)\n",
    "    reduced_logits = torch.stack(reduced_logits)\n",
    "    loss = self.loss_func(reduced_logits, labels)\n",
    "    return {\n",
    "      \"loss\": loss,\n",
    "      \"logits\": reduced_logits,\n",
    "      \"labels\": labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_iter(num_epochs, dataloader):\n",
    "    steps_per_epoch = len(dataloader)\n",
    "    for epoch in range(num_epochs):\n",
    "      for step in range(steps_per_epoch):\n",
    "        yield epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def eval_loop(model, dataloader, device):\n",
    "    \"\"\"Run validation phase.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # Keeping track of metrics\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0.0\n",
    "    total_count = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        batch = {key: val.to(device) if isinstance(val, torch.Tensor) else val for key, val in batch.items()}  \n",
    "        outputs = model(**batch)\n",
    "        loss = outputs[\"loss\"]\n",
    "\n",
    "        # Only count non-padding tokens\n",
    "        # (Same idea as ignore_index=PAD_IDX above)\n",
    "        preds = outputs['logits'].argmax(-1)\n",
    "        labels = outputs['labels']\n",
    "        correct_preds = (labels == preds).sum()\n",
    "        all_labels.append(labels)\n",
    "        all_preds.append(preds)\n",
    "\n",
    "        # Keeping track of metrics\n",
    "        total_loss += loss.item()\n",
    "        total_correct += correct_preds.item()\n",
    "        total_count += preds.shape[0]\n",
    "    all_labels = torch.cat(all_labels).cpu()\n",
    "    all_preds = torch.cat(all_preds).cpu()\n",
    "    return {\n",
    "        \"loss\": total_loss / total_count,\n",
    "        \"accuracy\": total_correct / total_count,\n",
    "        \"f1_score\": f1_score(all_labels, all_preds, average='macro')\n",
    "    }\n",
    "\n",
    "def train_step(optimizer, model, batch):\n",
    "    \"\"\"Run a single train step.\"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs[\"loss\"]\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(current_step: int, warmup_steps: int, total_steps: int, decay_type='linear'):\n",
    "    if current_step < warmup_steps:\n",
    "        return float(current_step) / float(max(1, warmup_steps))\n",
    "    if decay_type is None:\n",
    "        return 1.0\n",
    "    elif decay_type == 'linear':\n",
    "        w = - 1 / (total_steps - warmup_steps)\n",
    "        return (current_step - warmup_steps) * w + 1.0\n",
    "    elif decay_type == 'cosine':\n",
    "        w = np.pi / (total_steps - warmup_steps)\n",
    "        return 0.5 * np.cos(w * (current_step - warmup_steps)) + 0.5\n",
    "    else:\n",
    "        raise ValueError('invalid decay_type {} entered'.format(decay_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 5/450, val acc: 0.177, val f1: 0.133\n",
      "Step: 10/450, val acc: 0.531, val f1: 0.228\n",
      "Step: 15/450, val acc: 0.531, val f1: 0.228\n",
      "Step: 20/450, val acc: 0.521, val f1: 0.171\n",
      "Step: 25/450, val acc: 0.521, val f1: 0.171\n",
      "Step: 30/450, val acc: 0.521, val f1: 0.171\n",
      "Step: 35/450, val acc: 0.521, val f1: 0.171\n",
      "Step: 40/450, val acc: 0.531, val f1: 0.210\n",
      "Step: 45/450, val acc: 0.479, val f1: 0.212\n",
      "Step: 50/450, val acc: 0.500, val f1: 0.209\n",
      "Step: 55/450, val acc: 0.458, val f1: 0.196\n",
      "Step: 60/450, val acc: 0.521, val f1: 0.174\n",
      "Step: 65/450, val acc: 0.521, val f1: 0.174\n",
      "Step: 70/450, val acc: 0.510, val f1: 0.214\n",
      "Step: 75/450, val acc: 0.531, val f1: 0.193\n",
      "Step: 80/450, val acc: 0.562, val f1: 0.274\n",
      "Step: 85/450, val acc: 0.635, val f1: 0.345\n",
      "Step: 90/450, val acc: 0.594, val f1: 0.369\n",
      "Step: 95/450, val acc: 0.594, val f1: 0.306\n",
      "Step: 100/450, val acc: 0.542, val f1: 0.257\n",
      "Step: 105/450, val acc: 0.510, val f1: 0.197\n",
      "Step: 110/450, val acc: 0.500, val f1: 0.193\n",
      "Step: 115/450, val acc: 0.500, val f1: 0.277\n",
      "Step: 120/450, val acc: 0.500, val f1: 0.185\n",
      "Step: 125/450, val acc: 0.531, val f1: 0.193\n",
      "Step: 130/450, val acc: 0.542, val f1: 0.229\n",
      "Step: 135/450, val acc: 0.604, val f1: 0.333\n",
      "Step: 140/450, val acc: 0.562, val f1: 0.365\n",
      "Step: 145/450, val acc: 0.531, val f1: 0.302\n",
      "Step: 150/450, val acc: 0.562, val f1: 0.366\n",
      "Step: 155/450, val acc: 0.542, val f1: 0.280\n",
      "Step: 160/450, val acc: 0.542, val f1: 0.365\n",
      "Step: 165/450, val acc: 0.552, val f1: 0.295\n",
      "Step: 170/450, val acc: 0.552, val f1: 0.287\n",
      "Step: 175/450, val acc: 0.500, val f1: 0.186\n",
      "Step: 180/450, val acc: 0.542, val f1: 0.273\n",
      "Step: 185/450, val acc: 0.625, val f1: 0.340\n",
      "Step: 190/450, val acc: 0.562, val f1: 0.324\n",
      "Step: 195/450, val acc: 0.542, val f1: 0.327\n",
      "Step: 200/450, val acc: 0.562, val f1: 0.373\n",
      "Step: 205/450, val acc: 0.542, val f1: 0.330\n",
      "Step: 210/450, val acc: 0.542, val f1: 0.314\n",
      "Step: 215/450, val acc: 0.510, val f1: 0.315\n",
      "Step: 220/450, val acc: 0.542, val f1: 0.333\n",
      "Step: 225/450, val acc: 0.583, val f1: 0.319\n",
      "Step: 230/450, val acc: 0.615, val f1: 0.391\n",
      "Step: 235/450, val acc: 0.562, val f1: 0.394\n",
      "Step: 240/450, val acc: 0.354, val f1: 0.276\n",
      "Step: 245/450, val acc: 0.500, val f1: 0.348\n",
      "Step: 250/450, val acc: 0.594, val f1: 0.375\n",
      "Step: 255/450, val acc: 0.604, val f1: 0.346\n",
      "Step: 260/450, val acc: 0.604, val f1: 0.322\n",
      "Step: 265/450, val acc: 0.604, val f1: 0.321\n",
      "Step: 270/450, val acc: 0.625, val f1: 0.344\n",
      "Step: 275/450, val acc: 0.667, val f1: 0.471\n",
      "Step: 280/450, val acc: 0.667, val f1: 0.496\n",
      "Step: 285/450, val acc: 0.594, val f1: 0.444\n",
      "Step: 290/450, val acc: 0.542, val f1: 0.409\n",
      "Step: 295/450, val acc: 0.573, val f1: 0.420\n",
      "Step: 300/450, val acc: 0.604, val f1: 0.395\n",
      "Step: 305/450, val acc: 0.646, val f1: 0.453\n",
      "Step: 310/450, val acc: 0.656, val f1: 0.424\n",
      "Step: 315/450, val acc: 0.667, val f1: 0.396\n",
      "Step: 320/450, val acc: 0.677, val f1: 0.506\n",
      "Step: 325/450, val acc: 0.604, val f1: 0.392\n",
      "Step: 330/450, val acc: 0.552, val f1: 0.414\n",
      "Step: 335/450, val acc: 0.573, val f1: 0.449\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-34084ab53678>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mdataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         )\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/data/geraslab/ekr6072/miniconda3/envs/ds_1012/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-45808f0694c3>\u001b[0m in \u001b[0;36meval_loop\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/data/geraslab/ekr6072/miniconda3/envs/ds_1012/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-6458642b2a22>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mreduced_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mreduced_logits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10\n",
    "model = ClinicalBERT(5)\n",
    "optimizer = Adam(model.parameters(), lr=1e-4, weight_decay=1e-6)\n",
    "warmup_steps = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "timestamp = datetime.datetime.now()\n",
    "date = timestamp.strftime(\"%Y%m%d\")\n",
    "time = timestamp.strftime(\"%H%M%S\")\n",
    "save_path = f'./results/{date}/{time}'\n",
    "total_steps = NUM_EPOCHS * len(train_dataloader)\n",
    "lr_scheduler = None if warmup_steps is None \\\n",
    "                    else torch.optim.lr_scheduler.LambdaLR(optimizer, partial(lr_lambda, warmup_steps=warmup_steps, \n",
    "                                                                                         total_steps=total_steps))\n",
    "train_loss_list = []\n",
    "writer = SummaryWriter(log_dir=os.path.join(save_path, 'tb_logs'))\n",
    "model.to(device)\n",
    "for step, epoch, batch in zip(range(total_steps), epoch_iter(NUM_EPOCHS, train_dataloader), itertools.cycle(train_dataloader)):\n",
    "    batch = {key: val.to(device) if isinstance(val, torch.Tensor) else val for key, val in batch.items()}\n",
    "    loss_val = train_step(\n",
    "        optimizer=optimizer,\n",
    "        model=model,\n",
    "        batch=batch,\n",
    "    )\n",
    "    writer.add_scalar(\"learning_rate\", optimizer.param_groups[0]['lr'], step)\n",
    "    if lr_scheduler is not None:\n",
    "        lr_scheduler.step()\n",
    "\n",
    "    writer.add_scalar(\"epoch\", epoch, step)\n",
    "    writer.add_scalar(\"loss/train\", loss_val, step)\n",
    "    train_loss_list.append(loss_val)\n",
    "    if step % 5 == 0 and step != 0:\n",
    "        val_results = eval_loop(\n",
    "            model=model,\n",
    "            dataloader=val_dataloader,\n",
    "            device=device\n",
    "        )\n",
    "        for key, value in val_results.items():\n",
    "            writer.add_scalar(f\"{key}/val\", value, step)\n",
    "        print(\"Step: {}/{}, val acc: {:.3f}, val f1: {:.3f}\".format(\n",
    "            step, \n",
    "            total_steps,\n",
    "            val_results[\"accuracy\"],\n",
    "            val_results[\"f1_score\"])\n",
    "        )\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee3b5efc781680bf777f6c0f6ded34256a070c94fe240b983fb244a284c14fe0"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('ds_1012': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
